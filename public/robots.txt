# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To allow all web crawlers access to all content
User-agent: *
Disallow: /api/
Disallow: /_next/
